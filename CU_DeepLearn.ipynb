{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Powderblend_DeepLearning_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/PU_DL/blob/main/CU_DeepLearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaXKOMEbDrum"
      },
      "source": [
        "# **DEEP LEARNING BASED DRUG MIXING UNIFORMITY DETECTION IN BULK POWDER MIXTURE OF PHARMACEUTICAL FORMULATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPu9WZxHUc4A",
        "cellView": "form"
      },
      "source": [
        "#@title LOAD LIBRARIES\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8DsLdbzF2Bq",
        "cellView": "form"
      },
      "source": [
        "#@title DOWNLOAD DATA FROM KAGGLE\n",
        "# DOWNLOAD DATA FROM KAGGLE (!IMPORTANT!: REFRESH RUNTIME BEFORE RE-RUNNING THE CODE)\n",
        "#%%capture\n",
        "from google.colab import files\n",
        "files.upload()  #this will prompt you to upload the kaggle.json\n",
        "\n",
        "#Make Directory of Kaggle and set its permission for access.\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission\n",
        "\n",
        "# Download Data from Kaggle Fast and Unzip them in /content\n",
        "!kaggle datasets download -d drswayamprakashpatel/pu-deeplearn  -p /content\n",
        "\n",
        "#Unzip data (Two Folders - Training and Validation)\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#create a directory named train/\n",
        "!unzip -q pu-deeplearn.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBI7lNIlrSSx",
        "cellView": "form"
      },
      "source": [
        "#@title DOWNLOAD DATA FROM GOOGLE DRIVE - DO NOT RUN IF FOLLOW KAGGLE\n",
        "%%capture\n",
        "\n",
        "# DOWNLOAD DATA FROM GOOGLE DRIVE - NO NEED TO RUN IF FOLLOWING KAGGLE METHOD\n",
        "\n",
        "#Training Folder Download\n",
        "def folder_download(folder_id):\n",
        "  # authenticate\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  # get folder_name\n",
        "  from googleapiclient.discovery import build\n",
        "  service = build('drive', 'v3')\n",
        "  folder_name = service.files().get(fileId=folder_id).execute()['name']\n",
        "  # import library and download\n",
        "  !wget -qnc https://github.com/segnolin/google-drive-folder-downloader/raw/master/download.py\n",
        "  from download import download_folder\n",
        "  download_folder(service, folder_id, '/content/sample_data/', folder_name)\n",
        "  return folder_name\n",
        "folder_download('1zZFaYBPEAt-Os0hV1eqXSd8v9SoC-eja')\n",
        "\n",
        "#Validation Folder Download\n",
        "def folder_download(folder_id):\n",
        "  # authenticate\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  # get folder_name\n",
        "  from googleapiclient.discovery import build\n",
        "  service = build('drive', 'v3')\n",
        "  folder_name = service.files().get(fileId=folder_id).execute()['name']\n",
        "  # import library and download\n",
        "  !wget -qnc https://github.com/segnolin/google-drive-folder-downloader/raw/master/download.py\n",
        "  from download import download_folder\n",
        "  download_folder(service, folder_id, '/content/sample_data/', folder_name)\n",
        "  return folder_name\n",
        "folder_download('1vRM-HJ7cXzRMBVpzFKZq6QSIqKh5b_yh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFgPbskR2gRD",
        "cellView": "form"
      },
      "source": [
        "#@title JUST FOR UNDERSTANDING : HOW IMAGE GET COVERTED TO DATA\n",
        "#JUST FOR UNDERSTANDING : HOW IMAGE GET COVERTED TO DATA\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "# load the image\n",
        "img = load_img('/content/WhatsApp_Image_2021-08-18_at_3.34.57_PM__10__2.jpeg', grayscale= False)\n",
        "print(type(img))\n",
        "# convert to numpy array\n",
        "img_array = img_to_array(img)\n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "# convert back to image\n",
        "img_pil = array_to_img(img_array)\n",
        "print(type(img))\n",
        "plt.imshow(img_pil)\n",
        "print(img_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_P-QdvsUfEh",
        "cellView": "form"
      },
      "source": [
        "#@title IMAGE TO DATA, NORMALIZATION AND AUGMENTATION\n",
        "#Directories with Subdirectories as Classes for training and validation datasets\n",
        "%%capture\n",
        "train_dir = '/content/Dataset/Training'\n",
        "validation_dir = '/content/Dataset/Validation'\n",
        "\n",
        "# Set batch size and Image Height and Width\n",
        "batch_size = 10\n",
        "IMG_HEIGHT, IMG_WIDTH = (1000,1000)\n",
        "\n",
        "\n",
        "#Image to Data Transform using ImageDataGenerator of Keras\n",
        "\n",
        "#Image to Data for Training Data\n",
        "Dataset_Image_Training = ImageDataGenerator(rescale = 1./255, zoom_range=[0.8, 1.5], brightness_range= [0.8, 2.0])\n",
        "train_data_gen =  Dataset_Image_Training.flow_from_directory(\n",
        "                    batch_size= batch_size,\n",
        "                    directory=train_dir,\n",
        "                    shuffle=True,\n",
        "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                    class_mode='binary')\n",
        "#Image to Data for Validation Data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255, zoom_range=[0.8, 1.5], brightness_range= [0.8, 2.0])\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "                 batch_size=batch_size,\n",
        "                 directory= validation_dir,\n",
        "                 shuffle=True,\n",
        "                 target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                 class_mode= 'binary')\n",
        "#Check Classes in Dataset\n",
        "train_data_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6f_1troU2Q0",
        "cellView": "form"
      },
      "source": [
        "#@title Deep Learning CNN Model with Keras Seqential\n",
        "%%capture\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')])\n",
        "\n",
        "# Model Compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Tensorboard Set up\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#Checkpoint and earlystop setting\n",
        "filepath = '/content/drive/My Drive/DL_Model.hdf5'\n",
        "checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', save_best_only=True, Save_weights_only = False, verbose = 1), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience = 15, verbose =1), [tensorboard_callback]]\n",
        "\n",
        "#Model Fitting\n",
        "hist = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=500,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=None,\n",
        "    callbacks = [checkpoint]\n",
        ")\n",
        "\n",
        "#Accuracy Print\n",
        "\n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)\n",
        "\n",
        "#Load Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWxM1MCuhGyw"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(1000, 1000 ,3)),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RIkKSIOU8sI",
        "cellView": "form"
      },
      "source": [
        "#@title Prediction \n",
        "#Prediction\n",
        "#%%capture\n",
        "!mkdir -p /content/Prediction\n",
        "files.upload()\n",
        "!mv *.jpg /content/Prediction\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "IMG_HEIGHT, IMG_WIDTH = (100,100)\n",
        "\n",
        "Pred_Dir = '/content/Prediction'\n",
        "Prediction = ImageDataGenerator(rescale = 1./255)\n",
        "Pred_Data =  Prediction.flow_from_directory(\n",
        "                    directory=Pred_Dir,\n",
        "                    batch_size= batch_size,\n",
        "                    shuffle=False,\n",
        "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                    class_mode=None)\n",
        "#Pred_Data.reset()\n",
        "from keras.models import load_model\n",
        "\n",
        "#Download Model from Kaggle\n",
        "!kaggle datasets download -d adddatafilenamehere  -p /content\n",
        "#Unzip data\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#create a directory named train/\n",
        "!unzip -q DL_Model.zip\n",
        "\n",
        "model = load_model('/content/DL_Model.hdf5')\n",
        "Prediction = np.round(model.predict(Pred_Data))\n",
        "Prediction = np.any(Prediction, axis=1)\n",
        "\n",
        "train_data_gen.class_indices\n",
        "\n",
        "#Multiple images' prediction with image caption\n",
        "\n",
        "labels = ({'MIXED': 0, 'NOT MIXED': 1})\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in Prediction]\n",
        "filenames = Pred_Data.filenames\n",
        "results = pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}