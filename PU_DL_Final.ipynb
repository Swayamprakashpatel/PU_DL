{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Powderblend_DeepLearning_Keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/PU_DL/blob/main/PU_DL_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaXKOMEbDrum"
      },
      "source": [
        "# **DEEP LEARNING BASED DRUG MIXING UNIFORMITY DETECTION IN BULK POWDER MIXTURE OF PHARMACEUTICAL FORMULATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPu9WZxHUc4A",
        "cellView": "form"
      },
      "source": [
        "#@title LOAD LIBRARIES\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8DsLdbzF2Bq",
        "cellView": "form"
      },
      "source": [
        "#@title DOWNLOAD DATA FROM KAGGLE\n",
        "# DOWNLOAD DATA FROM KAGGLE (!IMPORTANT!: REFRESH RUNTIME BEFORE RE-RUNNING THE CODE)\n",
        "#%%capture\n",
        "from google.colab import files\n",
        "files.upload()  #this will prompt you to upload the kaggle.json\n",
        "\n",
        "#Make Directory of Kaggle and set its permission for access.\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission\n",
        "\n",
        "# Download Data from Kaggle Fast and Unzip them in /content\n",
        "!kaggle datasets download -d drswayamprakashpatel/pu-deeplearn  -p /content # For model download\n",
        "!kaggle datasets download -d drswayamprakashpatel/Dataset  -p /content # For Dataset download\n",
        "!kaggle datasets download -d drswayamprakashpatel/TestData  -p /content # For Test Dataset download\n",
        "#Unzip data (Two Folders - Training and Validation)\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#create a directory named train/\n",
        "!unzip -q pu-deeplearn.zip #Unzip Model\n",
        "!unzip -q Dataset.zip   #Unzip Dataset\n",
        "!unzip -q TestData.zip   #Unzip Test Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBI7lNIlrSSx",
        "cellView": "form"
      },
      "source": [
        "#@title DOWNLOAD DATA FROM GOOGLE DRIVE - DO NOT RUN IF FOLLOW KAGGLE\n",
        "%%capture\n",
        "\n",
        "# DOWNLOAD DATA FROM GOOGLE DRIVE - NO NEED TO RUN IF FOLLOWING KAGGLE METHOD\n",
        "\n",
        "#Training Folder Download\n",
        "def folder_download(folder_id):\n",
        "  # authenticate\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  # get folder_name\n",
        "  from googleapiclient.discovery import build\n",
        "  service = build('drive', 'v3')\n",
        "  folder_name = service.files().get(fileId=folder_id).execute()['name']\n",
        "  # import library and download\n",
        "  !wget -qnc https://github.com/segnolin/google-drive-folder-downloader/raw/master/download.py\n",
        "  from download import download_folder\n",
        "  download_folder(service, folder_id, '/content/sample_data/', folder_name)\n",
        "  return folder_name\n",
        "folder_download('1zZFaYBPEAt-Os0hV1eqXSd8v9SoC-eja')\n",
        "\n",
        "#Validation Folder Download\n",
        "def folder_download(folder_id):\n",
        "  # authenticate\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  # get folder_name\n",
        "  from googleapiclient.discovery import build\n",
        "  service = build('drive', 'v3')\n",
        "  folder_name = service.files().get(fileId=folder_id).execute()['name']\n",
        "  # import library and download\n",
        "  !wget -qnc https://github.com/segnolin/google-drive-folder-downloader/raw/master/download.py\n",
        "  from download import download_folder\n",
        "  download_folder(service, folder_id, '/content/sample_data/', folder_name)\n",
        "  return folder_name\n",
        "folder_download('1vRM-HJ7cXzRMBVpzFKZq6QSIqKh5b_yh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFgPbskR2gRD",
        "cellView": "form"
      },
      "source": [
        "#@title JUST FOR UNDERSTANDING : HOW IMAGE GET COVERTED TO DATA\n",
        "#JUST FOR UNDERSTANDING : HOW IMAGE GET COVERTED TO DATA\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "# load the image\n",
        "img = load_img('/content/WhatsApp_Image_2021-08-18_at_3.34.57_PM__10__2.jpeg', grayscale= False)\n",
        "print(type(img))\n",
        "# convert to numpy array\n",
        "img_array = img_to_array(img)\n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "# convert back to image\n",
        "img_pil = array_to_img(img_array)\n",
        "print(type(img))\n",
        "plt.imshow(img_pil)\n",
        "print(img_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_P-QdvsUfEh",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5070cf6c-a95c-434c-f9d8-6225b849f415"
      },
      "source": [
        "#@title IMAGE TO DATA, NORMALIZATION AND AUGMENTATION\n",
        "#Directories with Subdirectories as Classes for training and validation datasets\n",
        "#%%capture\n",
        "train_dir = '/content/Dataset/Training'\n",
        "validation_dir = '/content/Dataset/Validation'\n",
        "\n",
        "# Set batch size and Image Height and Width\n",
        "batch_size = 10\n",
        "IMG_HEIGHT, IMG_WIDTH = (1000,1000)\n",
        "\n",
        "\n",
        "#Image to Data Transform using ImageDataGenerator of Keras\n",
        "\n",
        "#Image to Data for Training Data\n",
        "Dataset_Image_Training = ImageDataGenerator(rescale = 1./255, zoom_range=[0.8, 1.5], brightness_range= [0.8, 2.0])\n",
        "train_data_gen =  Dataset_Image_Training.flow_from_directory(\n",
        "                    batch_size= batch_size,\n",
        "                    directory=train_dir,\n",
        "                    shuffle=True,\n",
        "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                    class_mode='binary')\n",
        "#Image to Data for Validation Data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255, zoom_range=[0.8, 1.5], brightness_range= [0.8, 2.0])\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "                 batch_size=batch_size,\n",
        "                 directory= validation_dir,\n",
        "                 shuffle=True,\n",
        "                 target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                 class_mode= 'binary')\n",
        "#Check Classes in Dataset\n",
        "train_data_gen.class_indices"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1181 images belonging to 2 classes.\n",
            "Found 410 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Mixed': 0, 'Not Mixed': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6f_1troU2Q0",
        "cellView": "form"
      },
      "source": [
        "#@title Deep Learning CNN Model with Keras Seqential\n",
        "#%%capture\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')])\n",
        "\n",
        "# Model Compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Tensorboard Set up\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#Checkpoint and earlystop setting\n",
        "filepath = '/content/drive/My Drive/DL_Model.hdf5'\n",
        "checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', save_best_only=True, Save_weights_only = False, verbose = 1), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience = 15, verbose =1), [tensorboard_callback]]\n",
        "\n",
        "#Model Fitting\n",
        "hist = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=500,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=None,\n",
        "    callbacks = [checkpoint]\n",
        ")\n",
        "\n",
        "#Accuracy Print\n",
        "\n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)\n",
        "\n",
        "#Load Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWxM1MCuhGyw",
        "cellView": "form"
      },
      "source": [
        "#@title Deep Learning CNN Model with Keras Seqential with **Dropout**\n",
        "#%%capture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')])\n",
        "\n",
        "# Model Compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Tensorboard Set up\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#Checkpoint and earlystop setting\n",
        "filepath = '/content/drive/My Drive/DL_Model.hdf5'\n",
        "checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', save_best_only=True, Save_weights_only = False, verbose = 1), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience = 15, verbose =1), [tensorboard_callback]]\n",
        "\n",
        "#Model Fitting\n",
        "hist = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=500,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=None,\n",
        "    callbacks = [checkpoint]\n",
        ")\n",
        "\n",
        "#Accuracy Print\n",
        "\n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)\n",
        "\n",
        "#Load Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "\n",
        "\n",
        "#Manual Plot\n",
        "#Training Accuracy vs Epoch\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc = 'upper left')\n",
        "plt.savefig(\"Training_Accuracy.svg\", format=\"svg\")\n",
        "plt.show()\n",
        "\n",
        "# Validation Accuracy vs Epoch\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['validation'], loc = 'upper left')\n",
        "plt.savefig(\"Validation_Accuracy.svg\", format=\"svg\")\n",
        "plt.show()\n",
        "\n",
        "#Training Loss vs Epoch\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc = 'upper left')\n",
        "plt.savefig(\"Training_Loss.svg\", format=\"svg\")\n",
        "plt.show()\n",
        "\n",
        "#Validation Loss vs Epoch\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['validation'], loc = 'upper left')\n",
        "plt.savefig(\"Validation_Loss.svg\", format=\"svg\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confution Matrix and Classification Report\n",
        "#%%capture\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
        "\n",
        "#Load test directory\n",
        "Pred_Dir = '/content/Dataset/Training'\n",
        "Prediction = ImageDataGenerator(rescale = 1./255)\n",
        "Pred_Data =  Prediction.flow_from_directory(\n",
        "                    directory=Pred_Dir,\n",
        "                    batch_size= batch_size,\n",
        "                    shuffle=False,\n",
        "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                    class_mode=None)\n",
        "\n",
        "model = load_model('/content/DL_Model.hdf5')\n",
        "Y_pred = np.round(model.predict(Pred_Data))\n",
        "y_pred = np.any(Y_pred, axis=1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(Pred_Data.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['Mixed', 'Not Mixed']\n",
        "#target_names =  list(train_data_gen.class_indices.keys()) #for large number of classes\n",
        "print(classification_report(Pred_Data.classes, y_pred, target_names=target_names))\n"
      ],
      "metadata": {
        "id": "w6k12tX9SWoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6ee2b2-df2a-4e6f-c98d-d779eff38832"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1181 images belonging to 2 classes.\n",
            "119/119 [==============================] - 703s 6s/step\n",
            "Confusion Matrix\n",
            "[[518  30]\n",
            " [  9 624]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Mixed       0.98      0.95      0.96       548\n",
            "   Not Mixed       0.95      0.99      0.97       633\n",
            "\n",
            "    accuracy                           0.97      1181\n",
            "   macro avg       0.97      0.97      0.97      1181\n",
            "weighted avg       0.97      0.97      0.97      1181\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RIkKSIOU8sI"
      },
      "source": [
        "#@title Prediction \n",
        "#Prediction\n",
        "#%%capture\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()  #this will prompt you to upload the kaggle.json\n",
        "\n",
        "#Make Directory of Kaggle and set its permission for access.\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission\n",
        "\n",
        "# Download Data from Kaggle Fast and Unzip them in /content\n",
        "!kaggle datasets download -d drswayamprakashpatel/pu-deeplearn  -p /content\n",
        "\n",
        "#Unzip data (Two Folders - Training and Validation)\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#create a directory named train/\n",
        "!unzip -q pu-deeplearn.zip\n",
        "\n",
        "#Make Directories for Test Image Prediction \n",
        "\n",
        "!mkdir -p /content/Prediction/Images\n",
        "files.upload()\n",
        "!mv *.jpg /content/Prediction/Images\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "IMG_HEIGHT, IMG_WIDTH = (1000,1000)\n",
        "\n",
        "Pred_Dir = '/content/Test Set'\n",
        "Prediction = ImageDataGenerator(rescale = 1./255)\n",
        "Pred_Data =  Prediction.flow_from_directory(\n",
        "                    directory=Pred_Dir,\n",
        "                    batch_size= batch_size,\n",
        "                    shuffle=False,\n",
        "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                    class_mode=None)\n",
        "\n",
        "#Pred_Data.reset()\n",
        "from keras.models import load_model\n",
        "\n",
        "#Download Model from Kaggle\n",
        "!kaggle datasets download -d adddatafilenamehere  -p /content\n",
        "#Unzip data\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#create a directory named train/\n",
        "!unzip -q DL_Model.zip\n",
        "\n",
        "model = load_model('/content/DL_Model.hdf5')\n",
        "Prediction = np.round(model.predict(Pred_Data))\n",
        "Prediction = np.any(Prediction, axis=1)\n",
        "\n",
        "#Multiple images' prediction with image caption\n",
        "\n",
        "labels = ({'MIXED': 0, 'NOT MIXED': 1})\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in Prediction]\n",
        "filenames = Pred_Data.filenames\n",
        "results = pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "IMG_HEIGHT, IMG_WIDTH = (1000,1000)\n",
        "\n",
        "Pred_Dir = '/content/TestData'\n",
        "Prediction = ImageDataGenerator(rescale = 1./255)\n",
        "Pred_Data =  Prediction.flow_from_directory(\n",
        "                    directory=Pred_Dir,\n",
        "                    batch_size= batch_size,\n",
        "                    shuffle=False,\n",
        "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
        "                    class_mode=None)\n",
        "\n",
        "#Pred_Data.reset()\n",
        "from keras.models import load_model\n",
        "\n",
        "#Download Model from Kaggle\n",
        "!kaggle datasets download -d adddatafilenamehere  -p /content\n",
        "#Unzip data\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#create a directory named train/\n",
        "!unzip -q DL_Model.zip\n",
        "\n",
        "model = load_model('/content/DL_Model.hdf5')\n",
        "Prediction = np.round(model.predict(Pred_Data))\n",
        "Prediction = np.any(Prediction, axis=1)\n",
        "\n",
        "#Multiple images' prediction with image caption\n",
        "\n",
        "labels = ({'MIXED': 0, 'NOT MIXED': 1})\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in Prediction]\n",
        "filenames = Pred_Data.filenames\n",
        "results = pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "print(results)"
      ],
      "metadata": {
        "id": "YNUvob7EWHVp",
        "outputId": "cfa36ea2-9860-41bb-948e-20a6230d8f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51 images belonging to 2 classes.\n",
            "403 - Forbidden\n",
            "unzip:  cannot find or open DL_Model.zip, DL_Model.zip.zip or DL_Model.zip.ZIP.\n",
            "6/6 [==============================] - 30s 5s/step\n",
            "                                    Filename Predictions\n",
            "0                                Mixed/M.jpg       MIXED\n",
            "1                   Mixed/Mixed_Test_1_1.jpg       MIXED\n",
            "2                   Mixed/Mixed_Test_1_2.jpg       MIXED\n",
            "3                   Mixed/Mixed_Test_1_3.jpg   NOT MIXED\n",
            "4                   Mixed/Mixed_Test_1_4.jpg   NOT MIXED\n",
            "5                   Mixed/Mixed_Test_1_5.jpg   NOT MIXED\n",
            "6                   Mixed/Mixed_Test_1_6.jpg   NOT MIXED\n",
            "7                 Mixed/TEst_M_08.10 (2).jpg       MIXED\n",
            "8                     Mixed/Test M_06.10.jpg       MIXED\n",
            "9                  Mixed/Test_M_08.10(3).jpg       MIXED\n",
            "10                 Mixed/Test_M_08.10(4).jpg       MIXED\n",
            "11                 Mixed/Test_M_08.10(5).jpg       MIXED\n",
            "12                 Mixed/Test_M_08.10(6).jpg   NOT MIXED\n",
            "13                 Mixed/Test_M_08.10(7).jpg   NOT MIXED\n",
            "14                 Mixed/Test_M_08.10(8).jpg       MIXED\n",
            "15                 Mixed/Test_M_08.10(9).jpg       MIXED\n",
            "16                    Mixed/Test_M_08.10.jpg       MIXED\n",
            "17               Mixed/Test_M_1_27.01.22.jpg       MIXED\n",
            "18               Mixed/Test_M_2_27.01.22.jpg       MIXED\n",
            "19               Mixed/Test_M_3_27.01.22.jpg       MIXED\n",
            "20               Mixed/Test_M_4_27.01.22.jpg       MIXED\n",
            "21               Mixed/Test_M_5_27.01.22.jpg       MIXED\n",
            "22               Mixed/Test_M_6_27.01.22.jpg   NOT MIXED\n",
            "23               Mixed/Test_M_7_27.01.22.jpg       MIXED\n",
            "24     Not Mixed/(TEST)_NM_batch-5_14.10.jpg   NOT MIXED\n",
            "25     Not Mixed/(TEST)_NM_batch-6_14.10.jpg   NOT MIXED\n",
            "26  Not Mixed/(TEST)_NM_batch-7(1)_18.10.jpg   NOT MIXED\n",
            "27  Not Mixed/(TEST)_NM_batch-7(2)_14.10.jpg   NOT MIXED\n",
            "28  Not Mixed/(TEST)_NM_batch-8(1)_19.10.jpg   NOT MIXED\n",
            "29  Not Mixed/(TEST)_NM_batch-8(2)_21.10.jpg   NOT MIXED\n",
            "30  Not Mixed/(TEST)_NM_batch-8(3)_21.10.jpg   NOT MIXED\n",
            "31  Not Mixed/(TEST)_NM_batch-9(1)_21.10.jpg   NOT MIXED\n",
            "32  Not Mixed/(TEST)_NM_batch-9(2)_21.10.jpg   NOT MIXED\n",
            "33                          Not Mixed/NM.jpg   NOT MIXED\n",
            "34          Not Mixed/NM_Test_1_1__4.10_.jpg   NOT MIXED\n",
            "35          Not Mixed/NM_Test_1_2__4.10_.jpg   NOT MIXED\n",
            "36          Not Mixed/NM_Test_1_3__4.10_.jpg   NOT MIXED\n",
            "37          Not Mixed/NM_Test_2_1__4.10_.jpg   NOT MIXED\n",
            "38          Not Mixed/NM_Test_2_2__4.10_.jpg       MIXED\n",
            "39          Not Mixed/NM_Test_2_3__4.10_.jpg   NOT MIXED\n",
            "40            Not Mixed/Test_NM_02.12(1).jpg   NOT MIXED\n",
            "41            Not Mixed/Test_NM_02.12(2).jpg   NOT MIXED\n",
            "42            Not Mixed/Test_NM_02.12(3).jpg   NOT MIXED\n",
            "43            Not Mixed/Test_NM_03.12(1).jpg   NOT MIXED\n",
            "44            Not Mixed/Test_NM_03.12(2).jpg   NOT MIXED\n",
            "45            Not Mixed/Test_NM_07.12(1).jpg   NOT MIXED\n",
            "46            Not Mixed/Test_NM_07.12(2).jpg   NOT MIXED\n",
            "47           Not Mixed/Test_NM_29.11 (1).jpg   NOT MIXED\n",
            "48            Not Mixed/Test_NM_29.11(2).jpg   NOT MIXED\n",
            "49            Not Mixed/Test_NM_29.11(3).jpg   NOT MIXED\n",
            "50            Not Mixed/Test_NM_29.11(4).jpg   NOT MIXED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXN2y1oEWHxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}